digraph {
	graph [size="156.75,156.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139694621684256 [label="
 ()" fillcolor=darkolivegreen1]
	139695153616160 [label=MeanBackward0]
	139695153617936 -> 139695153616160
	139695153617936 [label=AddmmBackward0]
	139695153615536 -> 139695153617936
	139694621610768 [label="module.linear.bias
 (10)" fillcolor=lightblue]
	139694621610768 -> 139695153615536
	139695153615536 [label=AccumulateGrad]
	139694523488864 -> 139695153617936
	139694523488864 [label=ViewBackward0]
	139694523488960 -> 139694523488864
	139694523488960 [label=AvgPool2DBackward0]
	139694523488624 -> 139694523488960
	139694523488624 [label=ReluBackward0]
	139694523488528 -> 139694523488624
	139694523488528 [label=CudnnBatchNormBackward0]
	139694523488384 -> 139694523488528
	139694523488384 [label=ConvolutionBackward0]
	139694523487712 -> 139694523488384
	139694523487712 [label=AddBackward0]
	139694523487664 -> 139694523487712
	139694523487664 [label=CudnnBatchNormBackward0]
	139694523487376 -> 139694523487664
	139694523487376 [label=ConvolutionBackward0]
	139694523488048 -> 139694523487376
	139694523488048 [label=ReluBackward0]
	139694523486800 -> 139694523488048
	139694523486800 [label=CudnnBatchNormBackward0]
	139694523488240 -> 139694523486800
	139694523488240 [label=ConvolutionBackward0]
	139694523489152 -> 139694523488240
	139694523489152 [label=ReluBackward0]
	139694523489296 -> 139694523489152
	139694523489296 [label=CudnnBatchNormBackward0]
	139694523489392 -> 139694523489296
	139694523489392 [label=ConvolutionBackward0]
	139694523489584 -> 139694523489392
	139694523489584 [label=AddBackward0]
	139694523489728 -> 139694523489584
	139694523489728 [label=CudnnBatchNormBackward0]
	139694523489872 -> 139694523489728
	139694523489872 [label=ConvolutionBackward0]
	139694523490064 -> 139694523489872
	139694523490064 [label=ReluBackward0]
	139694523490208 -> 139694523490064
	139694523490208 [label=CudnnBatchNormBackward0]
	139694523490256 -> 139694523490208
	139694523490256 [label=ConvolutionBackward0]
	139694621990336 -> 139694523490256
	139694621990336 [label=ReluBackward0]
	139694621990528 -> 139694621990336
	139694621990528 [label=CudnnBatchNormBackward0]
	139694621990384 -> 139694621990528
	139694621990384 [label=ConvolutionBackward0]
	139694523489680 -> 139694621990384
	139694523489680 [label=AddBackward0]
	139694621989760 -> 139694523489680
	139694621989760 [label=CudnnBatchNormBackward0]
	139694621990240 -> 139694621989760
	139694621990240 [label=ConvolutionBackward0]
	139694621989424 -> 139694621990240
	139694621989424 [label=ReluBackward0]
	139694621988320 -> 139694621989424
	139694621988320 [label=CudnnBatchNormBackward0]
	139694621988944 -> 139694621988320
	139694621988944 [label=ConvolutionBackward0]
	139694621988560 -> 139694621988944
	139694621988560 [label=ReluBackward0]
	139694621989712 -> 139694621988560
	139694621989712 [label=CudnnBatchNormBackward0]
	139694621990096 -> 139694621989712
	139694621990096 [label=ConvolutionBackward0]
	139694621990144 -> 139694621990096
	139694621990144 [label=CudnnBatchNormBackward0]
	139694621990672 -> 139694621990144
	139694621990672 [label=ConvolutionBackward0]
	139694621988752 -> 139694621990672
	139694621988752 [label=ReluBackward0]
	139694621988896 -> 139694621988752
	139694621988896 [label=CudnnBatchNormBackward0]
	139694621988800 -> 139694621988896
	139694621988800 [label=ConvolutionBackward0]
	139694621727808 -> 139694621988800
	139694621727808 [label=ReluBackward0]
	139694621728000 -> 139694621727808
	139694621728000 [label=CudnnBatchNormBackward0]
	139694621727568 -> 139694621728000
	139694621727568 [label=ConvolutionBackward0]
	139694621727472 -> 139694621727568
	139694621727472 [label=AddBackward0]
	139694621728240 -> 139694621727472
	139694621728240 [label=CudnnBatchNormBackward0]
	139694621728192 -> 139694621728240
	139694621728192 [label=ConvolutionBackward0]
	139694621728384 -> 139694621728192
	139694621728384 [label=ReluBackward0]
	139694621728720 -> 139694621728384
	139694621728720 [label=CudnnBatchNormBackward0]
	139694621728672 -> 139694621728720
	139694621728672 [label=ConvolutionBackward0]
	139694621724880 -> 139694621728672
	139694621724880 [label=ReluBackward0]
	139694621725024 -> 139694621724880
	139694621725024 [label=CudnnBatchNormBackward0]
	139694621725120 -> 139694621725024
	139694621725120 [label=ConvolutionBackward0]
	139694621727616 -> 139694621725120
	139694621727616 [label=AddBackward0]
	139694621725408 -> 139694621727616
	139694621725408 [label=CudnnBatchNormBackward0]
	139694621725552 -> 139694621725408
	139694621725552 [label=ConvolutionBackward0]
	139694621725744 -> 139694621725552
	139694621725744 [label=ReluBackward0]
	139694621725888 -> 139694621725744
	139694621725888 [label=CudnnBatchNormBackward0]
	139694621725984 -> 139694621725888
	139694621725984 [label=ConvolutionBackward0]
	139694621726176 -> 139694621725984
	139694621726176 [label=ReluBackward0]
	139694621726320 -> 139694621726176
	139694621726320 [label=CudnnBatchNormBackward0]
	139694621726416 -> 139694621726320
	139694621726416 [label=ConvolutionBackward0]
	139694621725360 -> 139694621726416
	139694621725360 [label=AddBackward0]
	139694621726704 -> 139694621725360
	139694621726704 [label=CudnnBatchNormBackward0]
	139694621726848 -> 139694621726704
	139694621726848 [label=ConvolutionBackward0]
	139694621727040 -> 139694621726848
	139694621727040 [label=ReluBackward0]
	139694621727184 -> 139694621727040
	139694621727184 [label=CudnnBatchNormBackward0]
	139694621727232 -> 139694621727184
	139694621727232 [label=ConvolutionBackward0]
	139700640804240 -> 139694621727232
	139700640804240 [label=ReluBackward0]
	139694621810896 -> 139700640804240
	139694621810896 [label=CudnnBatchNormBackward0]
	139694621810992 -> 139694621810896
	139694621810992 [label=ConvolutionBackward0]
	139694621811184 -> 139694621810992
	139694621811184 [label=AddBackward0]
	139694621811328 -> 139694621811184
	139694621811328 [label=CudnnBatchNormBackward0]
	139694621811472 -> 139694621811328
	139694621811472 [label=ConvolutionBackward0]
	139694621811664 -> 139694621811472
	139694621811664 [label=ReluBackward0]
	139694621811808 -> 139694621811664
	139694621811808 [label=CudnnBatchNormBackward0]
	139694621811904 -> 139694621811808
	139694621811904 [label=ConvolutionBackward0]
	139694621812096 -> 139694621811904
	139694621812096 [label=ReluBackward0]
	139694621812240 -> 139694621812096
	139694621812240 [label=CudnnBatchNormBackward0]
	139694621812336 -> 139694621812240
	139694621812336 [label=ConvolutionBackward0]
	139694621811280 -> 139694621812336
	139694621811280 [label=AddBackward0]
	139694621812624 -> 139694621811280
	139694621812624 [label=CudnnBatchNormBackward0]
	139694621812768 -> 139694621812624
	139694621812768 [label=ConvolutionBackward0]
	139694621812960 -> 139694621812768
	139694621812960 [label=ReluBackward0]
	139694621813104 -> 139694621812960
	139694621813104 [label=CudnnBatchNormBackward0]
	139694621813200 -> 139694621813104
	139694621813200 [label=ConvolutionBackward0]
	139694621813392 -> 139694621813200
	139694621813392 [label=ReluBackward0]
	139694621813536 -> 139694621813392
	139694621813536 [label=CudnnBatchNormBackward0]
	139694621813632 -> 139694621813536
	139694621813632 [label=ConvolutionBackward0]
	139694621812576 -> 139694621813632
	139694621812576 [label=AddBackward0]
	139694621813920 -> 139694621812576
	139694621813920 [label=CudnnBatchNormBackward0]
	139694621814064 -> 139694621813920
	139694621814064 [label=ConvolutionBackward0]
	139694621814256 -> 139694621814064
	139694621814256 [label=ReluBackward0]
	139694621814400 -> 139694621814256
	139694621814400 [label=CudnnBatchNormBackward0]
	139694621814496 -> 139694621814400
	139694621814496 [label=ConvolutionBackward0]
	139694621814688 -> 139694621814496
	139694621814688 [label=ReluBackward0]
	139694621814736 -> 139694621814688
	139694621814736 [label=CudnnBatchNormBackward0]
	139694621798608 -> 139694621814736
	139694621798608 [label=ConvolutionBackward0]
	139694621813872 -> 139694621798608
	139694621813872 [label=CudnnBatchNormBackward0]
	139694621798896 -> 139694621813872
	139694621798896 [label=ConvolutionBackward0]
	139694621799088 -> 139694621798896
	139694621799088 [label=ReluBackward0]
	139694621799232 -> 139694621799088
	139694621799232 [label=CudnnBatchNormBackward0]
	139694621799328 -> 139694621799232
	139694621799328 [label=ConvolutionBackward0]
	139694621799520 -> 139694621799328
	139694621799520 [label=ReluBackward0]
	139694621799664 -> 139694621799520
	139694621799664 [label=CudnnBatchNormBackward0]
	139694621799760 -> 139694621799664
	139694621799760 [label=ConvolutionBackward0]
	139694621799952 -> 139694621799760
	139694621799952 [label=AddBackward0]
	139694621800096 -> 139694621799952
	139694621800096 [label=CudnnBatchNormBackward0]
	139694621800240 -> 139694621800096
	139694621800240 [label=ConvolutionBackward0]
	139694621800432 -> 139694621800240
	139694621800432 [label=ReluBackward0]
	139694621800576 -> 139694621800432
	139694621800576 [label=CudnnBatchNormBackward0]
	139694621800672 -> 139694621800576
	139694621800672 [label=ConvolutionBackward0]
	139694621800864 -> 139694621800672
	139694621800864 [label=ReluBackward0]
	139694621801008 -> 139694621800864
	139694621801008 [label=CudnnBatchNormBackward0]
	139694621801104 -> 139694621801008
	139694621801104 [label=ConvolutionBackward0]
	139694621800048 -> 139694621801104
	139694621800048 [label=AddBackward0]
	139694621801392 -> 139694621800048
	139694621801392 [label=CudnnBatchNormBackward0]
	139694621801536 -> 139694621801392
	139694621801536 [label=ConvolutionBackward0]
	139694621801728 -> 139694621801536
	139694621801728 [label=ReluBackward0]
	139694621801872 -> 139694621801728
	139694621801872 [label=CudnnBatchNormBackward0]
	139694621801968 -> 139694621801872
	139694621801968 [label=ConvolutionBackward0]
	139694621802160 -> 139694621801968
	139694621802160 [label=ReluBackward0]
	139694621802304 -> 139694621802160
	139694621802304 [label=CudnnBatchNormBackward0]
	139694621802400 -> 139694621802304
	139694621802400 [label=ConvolutionBackward0]
	139694621801344 -> 139694621802400
	139694621801344 [label=CudnnBatchNormBackward0]
	139694621761792 -> 139694621801344
	139694621761792 [label=ConvolutionBackward0]
	139694621761984 -> 139694621761792
	139694621761984 [label=ReluBackward0]
	139694621762128 -> 139694621761984
	139694621762128 [label=CudnnBatchNormBackward0]
	139694621762224 -> 139694621762128
	139694621762224 [label=ConvolutionBackward0]
	139694621762416 -> 139694621762224
	139694621762416 [label=ReluBackward0]
	139694621762560 -> 139694621762416
	139694621762560 [label=CudnnBatchNormBackward0]
	139694621762656 -> 139694621762560
	139694621762656 [label=ConvolutionBackward0]
	139694621762848 -> 139694621762656
	139694621762848 [label=AddBackward0]
	139694621762992 -> 139694621762848
	139694621762992 [label=CudnnBatchNormBackward0]
	139694621763136 -> 139694621762992
	139694621763136 [label=ConvolutionBackward0]
	139694621763328 -> 139694621763136
	139694621763328 [label=ReluBackward0]
	139694621763472 -> 139694621763328
	139694621763472 [label=CudnnBatchNormBackward0]
	139694621763568 -> 139694621763472
	139694621763568 [label=ConvolutionBackward0]
	139694621763760 -> 139694621763568
	139694621763760 [label=ReluBackward0]
	139694621763904 -> 139694621763760
	139694621763904 [label=CudnnBatchNormBackward0]
	139694621764000 -> 139694621763904
	139694621764000 [label=ConvolutionBackward0]
	139694621762944 -> 139694621764000
	139694621762944 [label=AddBackward0]
	139694621764288 -> 139694621762944
	139694621764288 [label=CudnnBatchNormBackward0]
	139694621764432 -> 139694621764288
	139694621764432 [label=ConvolutionBackward0]
	139694621764624 -> 139694621764432
	139694621764624 [label=ReluBackward0]
	139694621764768 -> 139694621764624
	139694621764768 [label=CudnnBatchNormBackward0]
	139694621764864 -> 139694621764768
	139694621764864 [label=ConvolutionBackward0]
	139694621765056 -> 139694621764864
	139694621765056 [label=ReluBackward0]
	139694621765200 -> 139694621765056
	139694621765200 [label=CudnnBatchNormBackward0]
	139694621765296 -> 139694621765200
	139694621765296 [label=ConvolutionBackward0]
	139694621765488 -> 139694621765296
	139694621765488 [label=AddBackward0]
	139694621765584 -> 139694621765488
	139694621765584 [label=CudnnBatchNormBackward0]
	139694621708496 -> 139694621765584
	139694621708496 [label=ConvolutionBackward0]
	139694621708688 -> 139694621708496
	139694621708688 [label=ReluBackward0]
	139694621708832 -> 139694621708688
	139694621708832 [label=CudnnBatchNormBackward0]
	139694621708928 -> 139694621708832
	139694621708928 [label=ConvolutionBackward0]
	139694621709120 -> 139694621708928
	139694621709120 [label=ReluBackward0]
	139694621709264 -> 139694621709120
	139694621709264 [label=CudnnBatchNormBackward0]
	139694621709360 -> 139694621709264
	139694621709360 [label=ConvolutionBackward0]
	139694621709552 -> 139694621709360
	139694621709552 [label=ReluBackward0]
	139694621709696 -> 139694621709552
	139694621709696 [label=CudnnBatchNormBackward0]
	139694621709792 -> 139694621709696
	139694621709792 [label=ConvolutionBackward0]
	139694621709984 -> 139694621709792
	139695879045008 [label="module.conv1.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	139695879045008 -> 139694621709984
	139694621709984 [label=AccumulateGrad]
	139694621709744 -> 139694621709696
	139695879020688 [label="module.bn1.weight
 (32)" fillcolor=lightblue]
	139695879020688 -> 139694621709744
	139694621709744 [label=AccumulateGrad]
	139694621709600 -> 139694621709696
	139695879044768 [label="module.bn1.bias
 (32)" fillcolor=lightblue]
	139695879044768 -> 139694621709600
	139694621709600 [label=AccumulateGrad]
	139694621709504 -> 139694621709360
	139695879044368 [label="module.layers.0.conv1.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	139695879044368 -> 139694621709504
	139694621709504 [label=AccumulateGrad]
	139694621709312 -> 139694621709264
	139695879044288 [label="module.layers.0.bn1.weight
 (32)" fillcolor=lightblue]
	139695879044288 -> 139694621709312
	139694621709312 [label=AccumulateGrad]
	139694621709168 -> 139694621709264
	139695879044208 [label="module.layers.0.bn1.bias
 (32)" fillcolor=lightblue]
	139695879044208 -> 139694621709168
	139694621709168 [label=AccumulateGrad]
	139694621709072 -> 139694621708928
	139695879043728 [label="module.layers.0.conv2.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	139695879043728 -> 139694621709072
	139694621709072 [label=AccumulateGrad]
	139694621708880 -> 139694621708832
	139695879043808 [label="module.layers.0.bn2.weight
 (32)" fillcolor=lightblue]
	139695879043808 -> 139694621708880
	139694621708880 [label=AccumulateGrad]
	139694621708736 -> 139694621708832
	139695879043648 [label="module.layers.0.bn2.bias
 (32)" fillcolor=lightblue]
	139695879043648 -> 139694621708736
	139694621708736 [label=AccumulateGrad]
	139694621708640 -> 139694621708496
	139695879043248 [label="module.layers.0.conv3.weight
 (16, 32, 1, 1)" fillcolor=lightblue]
	139695879043248 -> 139694621708640
	139694621708640 [label=AccumulateGrad]
	139694621708448 -> 139694621765584
	139695879042688 [label="module.layers.0.bn3.weight
 (16)" fillcolor=lightblue]
	139695879042688 -> 139694621708448
	139694621708448 [label=AccumulateGrad]
	139694621708400 -> 139694621765584
	139695879042608 [label="module.layers.0.bn3.bias
 (16)" fillcolor=lightblue]
	139695879042608 -> 139694621708400
	139694621708400 [label=AccumulateGrad]
	139694621765536 -> 139694621765488
	139694621765536 [label=CudnnBatchNormBackward0]
	139694621709024 -> 139694621765536
	139694621709024 [label=ConvolutionBackward0]
	139694621709552 -> 139694621709024
	139694621709408 -> 139694621709024
	139695879042208 [label="module.layers.0.shortcut.0.weight
 (16, 32, 1, 1)" fillcolor=lightblue]
	139695879042208 -> 139694621709408
	139694621709408 [label=AccumulateGrad]
	139694621708592 -> 139694621765536
	139695879042128 [label="module.layers.0.shortcut.1.weight
 (16)" fillcolor=lightblue]
	139695879042128 -> 139694621708592
	139694621708592 [label=AccumulateGrad]
	139694621708544 -> 139694621765536
	139695879042048 [label="module.layers.0.shortcut.1.bias
 (16)" fillcolor=lightblue]
	139695879042048 -> 139694621708544
	139694621708544 [label=AccumulateGrad]
	139694621765440 -> 139694621765296
	139695879042928 [label="module.layers.1.conv1.weight
 (80, 16, 1, 1)" fillcolor=lightblue]
	139695879042928 -> 139694621765440
	139694621765440 [label=AccumulateGrad]
	139694621765248 -> 139694621765200
	139695879043168 [label="module.layers.1.bn1.weight
 (80)" fillcolor=lightblue]
	139695879043168 -> 139694621765248
	139694621765248 [label=AccumulateGrad]
	139694621765104 -> 139694621765200
	139695879043088 [label="module.layers.1.bn1.bias
 (80)" fillcolor=lightblue]
	139695879043088 -> 139694621765104
	139694621765104 [label=AccumulateGrad]
	139694621765008 -> 139694621764864
	139695878559280 [label="module.layers.1.conv2.weight
 (80, 1, 3, 3)" fillcolor=lightblue]
	139695878559280 -> 139694621765008
	139694621765008 [label=AccumulateGrad]
	139694621764816 -> 139694621764768
	139695878559360 [label="module.layers.1.bn2.weight
 (80)" fillcolor=lightblue]
	139695878559360 -> 139694621764816
	139694621764816 [label=AccumulateGrad]
	139694621764672 -> 139694621764768
	139695878559200 [label="module.layers.1.bn2.bias
 (80)" fillcolor=lightblue]
	139695878559200 -> 139694621764672
	139694621764672 [label=AccumulateGrad]
	139694621764576 -> 139694621764432
	139695878558800 [label="module.layers.1.conv3.weight
 (24, 80, 1, 1)" fillcolor=lightblue]
	139695878558800 -> 139694621764576
	139694621764576 [label=AccumulateGrad]
	139694621764384 -> 139694621764288
	139695878558720 [label="module.layers.1.bn3.weight
 (24)" fillcolor=lightblue]
	139695878558720 -> 139694621764384
	139694621764384 [label=AccumulateGrad]
	139694621764336 -> 139694621764288
	139695878558640 [label="module.layers.1.bn3.bias
 (24)" fillcolor=lightblue]
	139695878558640 -> 139694621764336
	139694621764336 [label=AccumulateGrad]
	139694621764240 -> 139694621762944
	139694621764240 [label=CudnnBatchNormBackward0]
	139694621764960 -> 139694621764240
	139694621764960 [label=ConvolutionBackward0]
	139694621765488 -> 139694621764960
	139694621765344 -> 139694621764960
	139695878558240 [label="module.layers.1.shortcut.0.weight
 (24, 16, 1, 1)" fillcolor=lightblue]
	139695878558240 -> 139694621765344
	139694621765344 [label=AccumulateGrad]
	139694621764528 -> 139694621764240
	139695878558160 [label="module.layers.1.shortcut.1.weight
 (24)" fillcolor=lightblue]
	139695878558160 -> 139694621764528
	139694621764528 [label=AccumulateGrad]
	139694621764480 -> 139694621764240
	139695878558080 [label="module.layers.1.shortcut.1.bias
 (24)" fillcolor=lightblue]
	139695878558080 -> 139694621764480
	139694621764480 [label=AccumulateGrad]
	139694621764192 -> 139694621764000
	139695878559520 [label="module.layers.2.conv1.weight
 (120, 24, 1, 1)" fillcolor=lightblue]
	139695878559520 -> 139694621764192
	139694621764192 [label=AccumulateGrad]
	139694621763952 -> 139694621763904
	139695878559440 [label="module.layers.2.bn1.weight
 (120)" fillcolor=lightblue]
	139695878559440 -> 139694621763952
	139694621763952 [label=AccumulateGrad]
	139694621763808 -> 139694621763904
	139695878560000 [label="module.layers.2.bn1.bias
 (120)" fillcolor=lightblue]
	139695878560000 -> 139694621763808
	139694621763808 [label=AccumulateGrad]
	139694621763712 -> 139694621763568
	139695879049280 [label="module.layers.2.conv2.weight
 (120, 1, 3, 3)" fillcolor=lightblue]
	139695879049280 -> 139694621763712
	139694621763712 [label=AccumulateGrad]
	139694621763520 -> 139694621763472
	139695879049360 [label="module.layers.2.bn2.weight
 (120)" fillcolor=lightblue]
	139695879049360 -> 139694621763520
	139694621763520 [label=AccumulateGrad]
	139694621763376 -> 139694621763472
	139695879049760 [label="module.layers.2.bn2.bias
 (120)" fillcolor=lightblue]
	139695879049760 -> 139694621763376
	139694621763376 [label=AccumulateGrad]
	139694621763280 -> 139694621763136
	139695879027184 [label="module.layers.2.conv3.weight
 (24, 120, 1, 1)" fillcolor=lightblue]
	139695879027184 -> 139694621763280
	139694621763280 [label=AccumulateGrad]
	139694621763088 -> 139694621762992
	139695879027344 [label="module.layers.2.bn3.weight
 (24)" fillcolor=lightblue]
	139695879027344 -> 139694621763088
	139694621763088 [label=AccumulateGrad]
	139694621763040 -> 139694621762992
	139695879027264 [label="module.layers.2.bn3.bias
 (24)" fillcolor=lightblue]
	139695879027264 -> 139694621763040
	139694621763040 [label=AccumulateGrad]
	139694621762944 -> 139694621762848
	139694621762800 -> 139694621762656
	139695879026624 [label="module.layers.3.conv1.weight
 (120, 24, 1, 1)" fillcolor=lightblue]
	139695879026624 -> 139694621762800
	139694621762800 [label=AccumulateGrad]
	139694621762608 -> 139694621762560
	139695879026544 [label="module.layers.3.bn1.weight
 (120)" fillcolor=lightblue]
	139695879026544 -> 139694621762608
	139694621762608 [label=AccumulateGrad]
	139694621762464 -> 139694621762560
	139695879026224 [label="module.layers.3.bn1.bias
 (120)" fillcolor=lightblue]
	139695879026224 -> 139694621762464
	139694621762464 [label=AccumulateGrad]
	139694621762368 -> 139694621762224
	139695879025744 [label="module.layers.3.conv2.weight
 (120, 1, 3, 3)" fillcolor=lightblue]
	139695879025744 -> 139694621762368
	139694621762368 [label=AccumulateGrad]
	139694621762176 -> 139694621762128
	139695879026064 [label="module.layers.3.bn2.weight
 (120)" fillcolor=lightblue]
	139695879026064 -> 139694621762176
	139694621762176 [label=AccumulateGrad]
	139694621762032 -> 139694621762128
	139695879025904 [label="module.layers.3.bn2.bias
 (120)" fillcolor=lightblue]
	139695879025904 -> 139694621762032
	139694621762032 [label=AccumulateGrad]
	139694621761936 -> 139694621761792
	139695879025264 [label="module.layers.3.conv3.weight
 (32, 120, 1, 1)" fillcolor=lightblue]
	139695879025264 -> 139694621761936
	139694621761936 [label=AccumulateGrad]
	139694621761744 -> 139694621801344
	139695879025424 [label="module.layers.3.bn3.weight
 (32)" fillcolor=lightblue]
	139695879025424 -> 139694621761744
	139694621761744 [label=AccumulateGrad]
	139694621761600 -> 139694621801344
	139695879025344 [label="module.layers.3.bn3.bias
 (32)" fillcolor=lightblue]
	139695879025344 -> 139694621761600
	139694621761600 [label=AccumulateGrad]
	139694621761696 -> 139694621802400
	139695879024944 [label="module.layers.4.conv1.weight
 (160, 32, 1, 1)" fillcolor=lightblue]
	139695879024944 -> 139694621761696
	139694621761696 [label=AccumulateGrad]
	139694621802352 -> 139694621802304
	139695879024864 [label="module.layers.4.bn1.weight
 (160)" fillcolor=lightblue]
	139695879024864 -> 139694621802352
	139694621802352 [label=AccumulateGrad]
	139694621802208 -> 139694621802304
	139695879024704 [label="module.layers.4.bn1.bias
 (160)" fillcolor=lightblue]
	139695879024704 -> 139694621802208
	139694621802208 [label=AccumulateGrad]
	139694621802112 -> 139694621801968
	139695879027744 [label="module.layers.4.conv2.weight
 (160, 1, 3, 3)" fillcolor=lightblue]
	139695879027744 -> 139694621802112
	139694621802112 [label=AccumulateGrad]
	139694621801920 -> 139694621801872
	139695879027824 [label="module.layers.4.bn2.weight
 (160)" fillcolor=lightblue]
	139695879027824 -> 139694621801920
	139694621801920 [label=AccumulateGrad]
	139694621801776 -> 139694621801872
	139695153715136 [label="module.layers.4.bn2.bias
 (160)" fillcolor=lightblue]
	139695153715136 -> 139694621801776
	139694621801776 [label=AccumulateGrad]
	139694621801680 -> 139694621801536
	139695153715536 [label="module.layers.4.conv3.weight
 (32, 160, 1, 1)" fillcolor=lightblue]
	139695153715536 -> 139694621801680
	139694621801680 [label=AccumulateGrad]
	139694621801488 -> 139694621801392
	139695153715616 [label="module.layers.4.bn3.weight
 (32)" fillcolor=lightblue]
	139695153715616 -> 139694621801488
	139694621801488 [label=AccumulateGrad]
	139694621801440 -> 139694621801392
	139695153715696 [label="module.layers.4.bn3.bias
 (32)" fillcolor=lightblue]
	139695153715696 -> 139694621801440
	139694621801440 [label=AccumulateGrad]
	139694621801344 -> 139694621800048
	139694621801296 -> 139694621801104
	139695153716096 [label="module.layers.5.conv1.weight
 (160, 32, 1, 1)" fillcolor=lightblue]
	139695153716096 -> 139694621801296
	139694621801296 [label=AccumulateGrad]
	139694621801056 -> 139694621801008
	139695153716176 [label="module.layers.5.bn1.weight
 (160)" fillcolor=lightblue]
	139695153716176 -> 139694621801056
	139694621801056 [label=AccumulateGrad]
	139694621800912 -> 139694621801008
	139695153716256 [label="module.layers.5.bn1.bias
 (160)" fillcolor=lightblue]
	139695153716256 -> 139694621800912
	139694621800912 [label=AccumulateGrad]
	139694621800816 -> 139694621800672
	139695153716736 [label="module.layers.5.conv2.weight
 (160, 1, 3, 3)" fillcolor=lightblue]
	139695153716736 -> 139694621800816
	139694621800816 [label=AccumulateGrad]
	139694621800624 -> 139694621800576
	139695153716656 [label="module.layers.5.bn2.weight
 (160)" fillcolor=lightblue]
	139695153716656 -> 139694621800624
	139694621800624 [label=AccumulateGrad]
	139694621800480 -> 139694621800576
	139695153716816 [label="module.layers.5.bn2.bias
 (160)" fillcolor=lightblue]
	139695153716816 -> 139694621800480
	139694621800480 [label=AccumulateGrad]
	139694621800384 -> 139694621800240
	139694622175296 [label="module.layers.5.conv3.weight
 (32, 160, 1, 1)" fillcolor=lightblue]
	139694622175296 -> 139694621800384
	139694621800384 [label=AccumulateGrad]
	139694621800192 -> 139694621800096
	139694622175376 [label="module.layers.5.bn3.weight
 (32)" fillcolor=lightblue]
	139694622175376 -> 139694621800192
	139694621800192 [label=AccumulateGrad]
	139694621800144 -> 139694621800096
	139694622175456 [label="module.layers.5.bn3.bias
 (32)" fillcolor=lightblue]
	139694622175456 -> 139694621800144
	139694621800144 [label=AccumulateGrad]
	139694621800048 -> 139694621799952
	139694621799904 -> 139694621799760
	139694622175856 [label="module.layers.6.conv1.weight
 (160, 32, 1, 1)" fillcolor=lightblue]
	139694622175856 -> 139694621799904
	139694621799904 [label=AccumulateGrad]
	139694621799712 -> 139694621799664
	139694622175936 [label="module.layers.6.bn1.weight
 (160)" fillcolor=lightblue]
	139694622175936 -> 139694621799712
	139694621799712 [label=AccumulateGrad]
	139694621799568 -> 139694621799664
	139694622176016 [label="module.layers.6.bn1.bias
 (160)" fillcolor=lightblue]
	139694622176016 -> 139694621799568
	139694621799568 [label=AccumulateGrad]
	139694621799472 -> 139694621799328
	139694622176496 [label="module.layers.6.conv2.weight
 (160, 1, 3, 3)" fillcolor=lightblue]
	139694622176496 -> 139694621799472
	139694621799472 [label=AccumulateGrad]
	139694621799280 -> 139694621799232
	139694622176416 [label="module.layers.6.bn2.weight
 (160)" fillcolor=lightblue]
	139694622176416 -> 139694621799280
	139694621799280 [label=AccumulateGrad]
	139694621799136 -> 139694621799232
	139694622176576 [label="module.layers.6.bn2.bias
 (160)" fillcolor=lightblue]
	139694622176576 -> 139694621799136
	139694621799136 [label=AccumulateGrad]
	139694621799040 -> 139694621798896
	139694622176976 [label="module.layers.6.conv3.weight
 (64, 160, 1, 1)" fillcolor=lightblue]
	139694622176976 -> 139694621799040
	139694621799040 [label=AccumulateGrad]
	139694621798848 -> 139694621813872
	139694622177056 [label="module.layers.6.bn3.weight
 (64)" fillcolor=lightblue]
	139694622177056 -> 139694621798848
	139694621798848 [label=AccumulateGrad]
	139694621798704 -> 139694621813872
	139694622177136 [label="module.layers.6.bn3.bias
 (64)" fillcolor=lightblue]
	139694622177136 -> 139694621798704
	139694621798704 [label=AccumulateGrad]
	139694621798800 -> 139694621798608
	139694622177536 [label="module.layers.7.conv1.weight
 (320, 64, 1, 1)" fillcolor=lightblue]
	139694622177536 -> 139694621798800
	139694621798800 [label=AccumulateGrad]
	139694621798560 -> 139694621814736
	139694622177616 [label="module.layers.7.bn1.weight
 (320)" fillcolor=lightblue]
	139694622177616 -> 139694621798560
	139694621798560 [label=AccumulateGrad]
	139694621798464 -> 139694621814736
	139694622177696 [label="module.layers.7.bn1.bias
 (320)" fillcolor=lightblue]
	139694622177696 -> 139694621798464
	139694621798464 [label=AccumulateGrad]
	139694621814640 -> 139694621814496
	139694622178176 [label="module.layers.7.conv2.weight
 (320, 1, 3, 3)" fillcolor=lightblue]
	139694622178176 -> 139694621814640
	139694621814640 [label=AccumulateGrad]
	139694621814448 -> 139694621814400
	139694622178096 [label="module.layers.7.bn2.weight
 (320)" fillcolor=lightblue]
	139694622178096 -> 139694621814448
	139694621814448 [label=AccumulateGrad]
	139694621814304 -> 139694621814400
	139694622178256 [label="module.layers.7.bn2.bias
 (320)" fillcolor=lightblue]
	139694622178256 -> 139694621814304
	139694621814304 [label=AccumulateGrad]
	139694621814208 -> 139694621814064
	139694622178656 [label="module.layers.7.conv3.weight
 (64, 320, 1, 1)" fillcolor=lightblue]
	139694622178656 -> 139694621814208
	139694621814208 [label=AccumulateGrad]
	139694621814016 -> 139694621813920
	139694622178736 [label="module.layers.7.bn3.weight
 (64)" fillcolor=lightblue]
	139694622178736 -> 139694621814016
	139694621814016 [label=AccumulateGrad]
	139694621813968 -> 139694621813920
	139694622178576 [label="module.layers.7.bn3.bias
 (64)" fillcolor=lightblue]
	139694622178576 -> 139694621813968
	139694621813968 [label=AccumulateGrad]
	139694621813872 -> 139694621812576
	139694621813824 -> 139694621813632
	139694622179216 [label="module.layers.8.conv1.weight
 (320, 64, 1, 1)" fillcolor=lightblue]
	139694622179216 -> 139694621813824
	139694621813824 [label=AccumulateGrad]
	139694621813584 -> 139694621813536
	139694622273600 [label="module.layers.8.bn1.weight
 (320)" fillcolor=lightblue]
	139694622273600 -> 139694621813584
	139694621813584 [label=AccumulateGrad]
	139694621813440 -> 139694621813536
	139694622273680 [label="module.layers.8.bn1.bias
 (320)" fillcolor=lightblue]
	139694622273680 -> 139694621813440
	139694621813440 [label=AccumulateGrad]
	139694621813344 -> 139694621813200
	139694622274160 [label="module.layers.8.conv2.weight
 (320, 1, 3, 3)" fillcolor=lightblue]
	139694622274160 -> 139694621813344
	139694621813344 [label=AccumulateGrad]
	139694621813152 -> 139694621813104
	139694622274080 [label="module.layers.8.bn2.weight
 (320)" fillcolor=lightblue]
	139694622274080 -> 139694621813152
	139694621813152 [label=AccumulateGrad]
	139694621813008 -> 139694621813104
	139694622274240 [label="module.layers.8.bn2.bias
 (320)" fillcolor=lightblue]
	139694622274240 -> 139694621813008
	139694621813008 [label=AccumulateGrad]
	139694621812912 -> 139694621812768
	139694622274640 [label="module.layers.8.conv3.weight
 (64, 320, 1, 1)" fillcolor=lightblue]
	139694622274640 -> 139694621812912
	139694621812912 [label=AccumulateGrad]
	139694621812720 -> 139694621812624
	139694622274720 [label="module.layers.8.bn3.weight
 (64)" fillcolor=lightblue]
	139694622274720 -> 139694621812720
	139694621812720 [label=AccumulateGrad]
	139694621812672 -> 139694621812624
	139694622274800 [label="module.layers.8.bn3.bias
 (64)" fillcolor=lightblue]
	139694622274800 -> 139694621812672
	139694621812672 [label=AccumulateGrad]
	139694621812576 -> 139694621811280
	139694621812528 -> 139694621812336
	139694622275200 [label="module.layers.9.conv1.weight
 (320, 64, 1, 1)" fillcolor=lightblue]
	139694622275200 -> 139694621812528
	139694621812528 [label=AccumulateGrad]
	139694621812288 -> 139694621812240
	139694622275280 [label="module.layers.9.bn1.weight
 (320)" fillcolor=lightblue]
	139694622275280 -> 139694621812288
	139694621812288 [label=AccumulateGrad]
	139694621812144 -> 139694621812240
	139694622275360 [label="module.layers.9.bn1.bias
 (320)" fillcolor=lightblue]
	139694622275360 -> 139694621812144
	139694621812144 [label=AccumulateGrad]
	139694621812048 -> 139694621811904
	139694622275840 [label="module.layers.9.conv2.weight
 (320, 1, 3, 3)" fillcolor=lightblue]
	139694622275840 -> 139694621812048
	139694621812048 [label=AccumulateGrad]
	139694621811856 -> 139694621811808
	139694622275760 [label="module.layers.9.bn2.weight
 (320)" fillcolor=lightblue]
	139694622275760 -> 139694621811856
	139694621811856 [label=AccumulateGrad]
	139694621811712 -> 139694621811808
	139694622275920 [label="module.layers.9.bn2.bias
 (320)" fillcolor=lightblue]
	139694622275920 -> 139694621811712
	139694621811712 [label=AccumulateGrad]
	139694621811616 -> 139694621811472
	139694622276320 [label="module.layers.9.conv3.weight
 (64, 320, 1, 1)" fillcolor=lightblue]
	139694622276320 -> 139694621811616
	139694621811616 [label=AccumulateGrad]
	139694621811424 -> 139694621811328
	139694622276400 [label="module.layers.9.bn3.weight
 (64)" fillcolor=lightblue]
	139694622276400 -> 139694621811424
	139694621811424 [label=AccumulateGrad]
	139694621811376 -> 139694621811328
	139694622276480 [label="module.layers.9.bn3.bias
 (64)" fillcolor=lightblue]
	139694622276480 -> 139694621811376
	139694621811376 [label=AccumulateGrad]
	139694621811280 -> 139694621811184
	139694621811136 -> 139694621810992
	139694622276880 [label="module.layers.10.conv1.weight
 (320, 64, 1, 1)" fillcolor=lightblue]
	139694622276880 -> 139694621811136
	139694621811136 [label=AccumulateGrad]
	139694621810944 -> 139694621810896
	139694622276960 [label="module.layers.10.bn1.weight
 (320)" fillcolor=lightblue]
	139694622276960 -> 139694621810944
	139694621810944 [label=AccumulateGrad]
	139694621810800 -> 139694621810896
	139694622277040 [label="module.layers.10.bn1.bias
 (320)" fillcolor=lightblue]
	139694622277040 -> 139694621810800
	139694621810800 [label=AccumulateGrad]
	139695176475360 -> 139694621727232
	139694622277520 [label="module.layers.10.conv2.weight
 (320, 1, 3, 3)" fillcolor=lightblue]
	139694622277520 -> 139695176475360
	139695176475360 [label=AccumulateGrad]
	139694621727088 -> 139694621727184
	139694622277440 [label="module.layers.10.bn2.weight
 (320)" fillcolor=lightblue]
	139694622277440 -> 139694621727088
	139694621727088 [label=AccumulateGrad]
	139695176476176 -> 139694621727184
	139694622363712 [label="module.layers.10.bn2.bias
 (320)" fillcolor=lightblue]
	139694622363712 -> 139695176476176
	139695176476176 [label=AccumulateGrad]
	139694621726992 -> 139694621726848
	139694622364112 [label="module.layers.10.conv3.weight
 (96, 320, 1, 1)" fillcolor=lightblue]
	139694622364112 -> 139694621726992
	139694621726992 [label=AccumulateGrad]
	139694621726800 -> 139694621726704
	139694622364192 [label="module.layers.10.bn3.weight
 (96)" fillcolor=lightblue]
	139694622364192 -> 139694621726800
	139694621726800 [label=AccumulateGrad]
	139694621726752 -> 139694621726704
	139694622364272 [label="module.layers.10.bn3.bias
 (96)" fillcolor=lightblue]
	139694622364272 -> 139694621726752
	139694621726752 [label=AccumulateGrad]
	139694621726656 -> 139694621725360
	139694621726656 [label=CudnnBatchNormBackward0]
	139695176475888 -> 139694621726656
	139695176475888 [label=ConvolutionBackward0]
	139694621811184 -> 139695176475888
	139694621811040 -> 139695176475888
	139694622364672 [label="module.layers.10.shortcut.0.weight
 (96, 64, 1, 1)" fillcolor=lightblue]
	139694622364672 -> 139694621811040
	139694621811040 [label=AccumulateGrad]
	139694621726944 -> 139694621726656
	139694622364752 [label="module.layers.10.shortcut.1.weight
 (96)" fillcolor=lightblue]
	139694622364752 -> 139694621726944
	139694621726944 [label=AccumulateGrad]
	139694621726896 -> 139694621726656
	139694622364832 [label="module.layers.10.shortcut.1.bias
 (96)" fillcolor=lightblue]
	139694622364832 -> 139694621726896
	139694621726896 [label=AccumulateGrad]
	139694621726608 -> 139694621726416
	139694622365232 [label="module.layers.11.conv1.weight
 (480, 96, 1, 1)" fillcolor=lightblue]
	139694622365232 -> 139694621726608
	139694621726608 [label=AccumulateGrad]
	139694621726368 -> 139694621726320
	139694622365312 [label="module.layers.11.bn1.weight
 (480)" fillcolor=lightblue]
	139694622365312 -> 139694621726368
	139694621726368 [label=AccumulateGrad]
	139694621726224 -> 139694621726320
	139694622365392 [label="module.layers.11.bn1.bias
 (480)" fillcolor=lightblue]
	139694622365392 -> 139694621726224
	139694621726224 [label=AccumulateGrad]
	139694621726128 -> 139694621725984
	139694622365872 [label="module.layers.11.conv2.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	139694622365872 -> 139694621726128
	139694621726128 [label=AccumulateGrad]
	139694621725936 -> 139694621725888
	139694622365792 [label="module.layers.11.bn2.weight
 (480)" fillcolor=lightblue]
	139694622365792 -> 139694621725936
	139694621725936 [label=AccumulateGrad]
	139694621725792 -> 139694621725888
	139694622365952 [label="module.layers.11.bn2.bias
 (480)" fillcolor=lightblue]
	139694622365952 -> 139694621725792
	139694621725792 [label=AccumulateGrad]
	139694621725696 -> 139694621725552
	139694622366352 [label="module.layers.11.conv3.weight
 (96, 480, 1, 1)" fillcolor=lightblue]
	139694622366352 -> 139694621725696
	139694621725696 [label=AccumulateGrad]
	139694621725504 -> 139694621725408
	139694622366432 [label="module.layers.11.bn3.weight
 (96)" fillcolor=lightblue]
	139694622366432 -> 139694621725504
	139694621725504 [label=AccumulateGrad]
	139694621725456 -> 139694621725408
	139694622366512 [label="module.layers.11.bn3.bias
 (96)" fillcolor=lightblue]
	139694622366512 -> 139694621725456
	139694621725456 [label=AccumulateGrad]
	139694621725360 -> 139694621727616
	139694621725312 -> 139694621725120
	139694622366912 [label="module.layers.12.conv1.weight
 (480, 96, 1, 1)" fillcolor=lightblue]
	139694622366912 -> 139694621725312
	139694621725312 [label=AccumulateGrad]
	139694621725072 -> 139694621725024
	139694622366992 [label="module.layers.12.bn1.weight
 (480)" fillcolor=lightblue]
	139694622366992 -> 139694621725072
	139694621725072 [label=AccumulateGrad]
	139694621724928 -> 139694621725024
	139694622367072 [label="module.layers.12.bn1.bias
 (480)" fillcolor=lightblue]
	139694622367072 -> 139694621724928
	139694621724928 [label=AccumulateGrad]
	139694621724832 -> 139694621728672
	139694622367552 [label="module.layers.12.conv2.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	139694622367552 -> 139694621724832
	139694621724832 [label=AccumulateGrad]
	139694621728576 -> 139694621728720
	139694622367472 [label="module.layers.12.bn2.weight
 (480)" fillcolor=lightblue]
	139694622367472 -> 139694621728576
	139694621728576 [label=AccumulateGrad]
	139694621728624 -> 139694621728720
	139694622367632 [label="module.layers.12.bn2.bias
 (480)" fillcolor=lightblue]
	139694622367632 -> 139694621728624
	139694621728624 [label=AccumulateGrad]
	139694621728528 -> 139694621728192
	139694621925760 [label="module.layers.12.conv3.weight
 (96, 480, 1, 1)" fillcolor=lightblue]
	139694621925760 -> 139694621728528
	139694621728528 [label=AccumulateGrad]
	139694621728336 -> 139694621728240
	139694621925840 [label="module.layers.12.bn3.weight
 (96)" fillcolor=lightblue]
	139694621925840 -> 139694621728336
	139694621728336 [label=AccumulateGrad]
	139694621728096 -> 139694621728240
	139694621925920 [label="module.layers.12.bn3.bias
 (96)" fillcolor=lightblue]
	139694621925920 -> 139694621728096
	139694621728096 [label=AccumulateGrad]
	139694621727616 -> 139694621727472
	139694621728144 -> 139694621727568
	139694621926320 [label="module.layers.13.conv1.weight
 (480, 96, 1, 1)" fillcolor=lightblue]
	139694621926320 -> 139694621728144
	139694621728144 [label=AccumulateGrad]
	139694621727424 -> 139694621728000
	139694621926400 [label="module.layers.13.bn1.weight
 (480)" fillcolor=lightblue]
	139694621926400 -> 139694621727424
	139694621727424 [label=AccumulateGrad]
	139694621727952 -> 139694621728000
	139694621926480 [label="module.layers.13.bn1.bias
 (480)" fillcolor=lightblue]
	139694621926480 -> 139694621727952
	139694621727952 [label=AccumulateGrad]
	139694621727328 -> 139694621988800
	139694621926960 [label="module.layers.13.conv2.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	139694621926960 -> 139694621727328
	139694621727328 [label=AccumulateGrad]
	139694621727712 -> 139694621988896
	139694621926880 [label="module.layers.13.bn2.weight
 (480)" fillcolor=lightblue]
	139694621926880 -> 139694621727712
	139694621727712 [label=AccumulateGrad]
	139694621727904 -> 139694621988896
	139694621927040 [label="module.layers.13.bn2.bias
 (480)" fillcolor=lightblue]
	139694621927040 -> 139694621727904
	139694621727904 [label=AccumulateGrad]
	139694621989136 -> 139694621990672
	139694621927440 [label="module.layers.13.conv3.weight
 (160, 480, 1, 1)" fillcolor=lightblue]
	139694621927440 -> 139694621989136
	139694621989136 [label=AccumulateGrad]
	139694621990720 -> 139694621990144
	139694621927520 [label="module.layers.13.bn3.weight
 (160)" fillcolor=lightblue]
	139694621927520 -> 139694621990720
	139694621990720 [label=AccumulateGrad]
	139694621989232 -> 139694621990144
	139694621927600 [label="module.layers.13.bn3.bias
 (160)" fillcolor=lightblue]
	139694621927600 -> 139694621989232
	139694621989232 [label=AccumulateGrad]
	139694621988992 -> 139694621990096
	139694621928000 [label="module.layers.14.conv1.weight
 (800, 160, 1, 1)" fillcolor=lightblue]
	139694621928000 -> 139694621988992
	139694621988992 [label=AccumulateGrad]
	139694621989904 -> 139694621989712
	139694621928080 [label="module.layers.14.bn1.weight
 (800)" fillcolor=lightblue]
	139694621928080 -> 139694621989904
	139694621989904 [label=AccumulateGrad]
	139694621988368 -> 139694621989712
	139694621928160 [label="module.layers.14.bn1.bias
 (800)" fillcolor=lightblue]
	139694621928160 -> 139694621988368
	139694621988368 [label=AccumulateGrad]
	139694621989376 -> 139694621988944
	139694621928640 [label="module.layers.14.conv2.weight
 (800, 1, 3, 3)" fillcolor=lightblue]
	139694621928640 -> 139694621989376
	139694621989376 [label=AccumulateGrad]
	139694621989280 -> 139694621988320
	139694621928560 [label="module.layers.14.bn2.weight
 (800)" fillcolor=lightblue]
	139694621928560 -> 139694621989280
	139694621989280 [label=AccumulateGrad]
	139694621989184 -> 139694621988320
	139694621928720 [label="module.layers.14.bn2.bias
 (800)" fillcolor=lightblue]
	139694621928720 -> 139694621989184
	139694621989184 [label=AccumulateGrad]
	139694621989520 -> 139694621990240
	139694621929120 [label="module.layers.14.conv3.weight
 (160, 800, 1, 1)" fillcolor=lightblue]
	139694621929120 -> 139694621989520
	139694621989520 [label=AccumulateGrad]
	139694621990192 -> 139694621989760
	139694621929200 [label="module.layers.14.bn3.weight
 (160)" fillcolor=lightblue]
	139694621929200 -> 139694621990192
	139694621990192 [label=AccumulateGrad]
	139694621989808 -> 139694621989760
	139694621929280 [label="module.layers.14.bn3.bias
 (160)" fillcolor=lightblue]
	139694621929280 -> 139694621989808
	139694621989808 [label=AccumulateGrad]
	139694621990144 -> 139694523489680
	139694621990048 -> 139694621990384
	139694622019888 [label="module.layers.15.conv1.weight
 (800, 160, 1, 1)" fillcolor=lightblue]
	139694622019888 -> 139694621990048
	139694621990048 [label=AccumulateGrad]
	139694621989952 -> 139694621990528
	139694622019968 [label="module.layers.15.bn1.weight
 (800)" fillcolor=lightblue]
	139694622019968 -> 139694621989952
	139694621989952 [label=AccumulateGrad]
	139694621990432 -> 139694621990528
	139694622020048 [label="module.layers.15.bn1.bias
 (800)" fillcolor=lightblue]
	139694622020048 -> 139694621990432
	139694621990432 [label=AccumulateGrad]
	139694621989664 -> 139694523490256
	139694622020528 [label="module.layers.15.conv2.weight
 (800, 1, 3, 3)" fillcolor=lightblue]
	139694622020528 -> 139694621989664
	139694621989664 [label=AccumulateGrad]
	139694523490112 -> 139694523490208
	139694622020448 [label="module.layers.15.bn2.weight
 (800)" fillcolor=lightblue]
	139694622020448 -> 139694523490112
	139694523490112 [label=AccumulateGrad]
	139694621989472 -> 139694523490208
	139694622020608 [label="module.layers.15.bn2.bias
 (800)" fillcolor=lightblue]
	139694622020608 -> 139694621989472
	139694621989472 [label=AccumulateGrad]
	139694523490016 -> 139694523489872
	139694622021008 [label="module.layers.15.conv3.weight
 (160, 800, 1, 1)" fillcolor=lightblue]
	139694622021008 -> 139694523490016
	139694523490016 [label=AccumulateGrad]
	139694523489824 -> 139694523489728
	139694622021088 [label="module.layers.15.bn3.weight
 (160)" fillcolor=lightblue]
	139694622021088 -> 139694523489824
	139694523489824 [label=AccumulateGrad]
	139694523489776 -> 139694523489728
	139694622021168 [label="module.layers.15.bn3.bias
 (160)" fillcolor=lightblue]
	139694622021168 -> 139694523489776
	139694523489776 [label=AccumulateGrad]
	139694523489680 -> 139694523489584
	139694523489536 -> 139694523489392
	139694622021568 [label="module.layers.16.conv1.weight
 (800, 160, 1, 1)" fillcolor=lightblue]
	139694622021568 -> 139694523489536
	139694523489536 [label=AccumulateGrad]
	139694523489344 -> 139694523489296
	139694622021648 [label="module.layers.16.bn1.weight
 (800)" fillcolor=lightblue]
	139694622021648 -> 139694523489344
	139694523489344 [label=AccumulateGrad]
	139694523489200 -> 139694523489296
	139694622021728 [label="module.layers.16.bn1.bias
 (800)" fillcolor=lightblue]
	139694622021728 -> 139694523489200
	139694523489200 [label=AccumulateGrad]
	139694523489104 -> 139694523488240
	139694622022208 [label="module.layers.16.conv2.weight
 (800, 1, 3, 3)" fillcolor=lightblue]
	139694622022208 -> 139694523489104
	139694523489104 [label=AccumulateGrad]
	139694523488336 -> 139694523486800
	139694622022128 [label="module.layers.16.bn2.weight
 (800)" fillcolor=lightblue]
	139694622022128 -> 139694523488336
	139694523488336 [label=AccumulateGrad]
	139694523487856 -> 139694523486800
	139694622022288 [label="module.layers.16.bn2.bias
 (800)" fillcolor=lightblue]
	139694622022288 -> 139694523487856
	139694523487856 [label=AccumulateGrad]
	139694523487472 -> 139694523487376
	139694622022688 [label="module.layers.16.conv3.weight
 (320, 800, 1, 1)" fillcolor=lightblue]
	139694622022688 -> 139694523487472
	139694523487472 [label=AccumulateGrad]
	139694523486704 -> 139694523487664
	139694622022768 [label="module.layers.16.bn3.weight
 (320)" fillcolor=lightblue]
	139694622022768 -> 139694523486704
	139694523486704 [label=AccumulateGrad]
	139694523487952 -> 139694523487664
	139694622022848 [label="module.layers.16.bn3.bias
 (320)" fillcolor=lightblue]
	139694622022848 -> 139694523487952
	139694523487952 [label=AccumulateGrad]
	139694523487616 -> 139694523487712
	139694523487616 [label=CudnnBatchNormBackward0]
	139694523488816 -> 139694523487616
	139694523488816 [label=ConvolutionBackward0]
	139694523489584 -> 139694523488816
	139694523489248 -> 139694523488816
	139694622023248 [label="module.layers.16.shortcut.0.weight
 (320, 160, 1, 1)" fillcolor=lightblue]
	139694622023248 -> 139694523489248
	139694523489248 [label=AccumulateGrad]
	139694523487424 -> 139694523487616
	139694622023328 [label="module.layers.16.shortcut.1.weight
 (320)" fillcolor=lightblue]
	139694622023328 -> 139694523487424
	139694523487424 [label=AccumulateGrad]
	139694523487808 -> 139694523487616
	139694622023408 [label="module.layers.16.shortcut.1.bias
 (320)" fillcolor=lightblue]
	139694622023408 -> 139694523487808
	139694523487808 [label=AccumulateGrad]
	139694523488096 -> 139694523488384
	139694621610208 [label="module.conv2.weight
 (1280, 320, 1, 1)" fillcolor=lightblue]
	139694621610208 -> 139694523488096
	139694523488096 [label=AccumulateGrad]
	139694523488480 -> 139694523488528
	139694621610288 [label="module.bn2.weight
 (1280)" fillcolor=lightblue]
	139694621610288 -> 139694523488480
	139694523488480 [label=AccumulateGrad]
	139694523488720 -> 139694523488528
	139694621610368 [label="module.bn2.bias
 (1280)" fillcolor=lightblue]
	139694621610368 -> 139694523488720
	139694523488720 [label=AccumulateGrad]
	139694523489056 -> 139695153617936
	139694523489056 [label=TBackward0]
	139694523488576 -> 139694523489056
	139694621610688 [label="module.linear.weight
 (10, 1280)" fillcolor=lightblue]
	139694621610688 -> 139694523488576
	139694523488576 [label=AccumulateGrad]
	139695153616160 -> 139694621684256
}
